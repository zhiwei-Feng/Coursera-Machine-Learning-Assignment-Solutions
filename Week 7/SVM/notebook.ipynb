{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Large Margin Classification\n",
    "\n",
    "__SVM Hypothesis__\n",
    "\n",
    "$\\min _{\\theta} C \\sum_{i=1}^{m} [y^{(i)} cost_1 (\\theta^Tx^{(i)})+ (1-y^{(i)}) cost_0 (\\theta^Tx^{(i)})] +\\frac{1}{2} \\sum_{i=1}^{n} \\theta_{j}^{2}$\n",
    "\n",
    "> $C$ is similar to $\\frac{1}{\\lambda}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kernels\n",
    "\n",
    "1. choice some landmarks $l^{(1)}, l^{(2)}, l^{(3)}$\n",
    "2. $f_i = similarity(x,l^{(i)}) = exp(-\\frac{||x-l^{(i)}||^2}{2\\delta^2})$\n",
    "\n",
    "__SVM with Kernels__\n",
    "\n",
    "Given $\\left(x^{(1)}, y^{(1)}\\right),\\left(x^{(2)}, y^{(2)}\\right), \\ldots,\\left(x^{(m)}, y^{(m)}\\right)$\n",
    "\n",
    "choose $l^{(1)}=x^{(1)}, l^{(2)}=x^{(2)}, \\ldots, l^{(m)}=x^{(m)}$\n",
    "\n",
    "Given example $x$:\n",
    "\n",
    "$f_i = similarity(x,l^{(i)})$\n",
    "\n",
    "__Training:__\n",
    "\n",
    "$\\min _{\\theta} C \\sum_{i=1}^{m} [y^{(i)} cost_1 (\\theta^Tf^{(i)})+ (1-y^{(i)}) cost_0 (\\theta^Tf^{(i)})] +\\frac{1}{2} \\sum_{i=1}^{n} \\theta_{j}^{2}$\n",
    "\n",
    "__SVM parameters__\n",
    "\n",
    "C ($ = \\frac{1}{\\lambda}$)\n",
    "\n",
    "Large C: Lower bias, Higher variance\n",
    "Small C: Lower variance, Higher bias\n",
    "\n",
    "$\\delta^2$\n",
    "\n",
    "Large $\\delta^2$: Higher bias , Lower variance\n",
    "Small $\\delta^2$: Lower bias , Higher variance "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Using An SVM\n",
    "\n",
    "use SVM software package to solve for parameters $\\theta$\n",
    "\n",
    "Need to specify:\n",
    "\n",
    "- Choice of parameter $C$\n",
    "- Choice of kernel (similarity function)\n",
    "\n",
    "E.g. No kernel (\"linear kernel\")\n",
    "\n",
    "Gaussian Kernel:\n",
    "\n",
    "$f_{i}=\\exp \\left(-\\frac{\\|x-l^{(i)}\\|^{2}}{2 \\sigma^{2}}\\right),$ where $l^{(i)}=x^{(i)}$\n",
    "\n",
    "Need to choose $\\delta^2$\n",
    "\n",
    "> Do  perform  feature  scaling  before  using  the  Gaussian  kernel. \n",
    "\n",
    "__Logistic regression vs. SVMs__\n",
    "\n",
    "_n_ = number of features, _m_ = number of training examples\n",
    "\n",
    "1. if $n$ is large (relative to $m$):\n",
    "\n",
    "use logistic regression , or SVM without kernel\n",
    "\n",
    "2. if $n$ is small, $m$ is intermediate:\n",
    "\n",
    "use SVM with Gaussian Kernel\n",
    "\n",
    "3. if $n$ is small, $m$ is large:\n",
    "\n",
    "create/add more features, then use logistic regression or SVM without a kernel\n",
    "\n",
    "> Neural  network  likely  to  work  well  for  most  of  these  settings,  but  may  be \n",
    "slower  to  train. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}